<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
</head>

<body style="background-color: aliceblue;">
    <h1>Data Integration</h1>
    <p>
        In this course, we have discussed and explored various aspects of data collection, storage, and analysis.
        However, the real value of data lies in its integration and exchange across different systems and platforms.
        Data integration, or combining data from multiple sources into a unified view, enabling organizations to
        have access to accurate and comprehensive information. This integrated data can then be used for various
        purposes, including decision-making, reporting, and analysis.
    </p>
    <p>
        We have looked examples of data collection and hosted data sets. And focused on data storage.
    </p>
    <p>
        Considering database architecture, you have seen the basic structure of client-server architecture and how
        separating the data and the processing from the user interface can improve performance and scalability. This
        separation also enables data integration by allowing different systems to access and interact with the same data
        source.
    </p>
    <p>&nbsp;</p>
    <h2>Why Data Integration Matters</h2>
    <p>
        Data integration is essential for organizations that rely on data-driven insights to make informed decisions. By
        combining data from disparate sources, organizations can gain a more complete and accurate understanding of
        their operations, customers, and market trends. This integrated view of data enables organizations to identify
        patterns, trends, and correlations that would be difficult to discern from individual data silos.
    </p>
    <p>
        In the context of business intelligence and analytics, data integration is critical for creating a single source
        of truth that can be used for reporting and analysis. Without data integration, organizations risk making
        decisions based on incomplete or inaccurate information, leading to undesirable outcomes.
    </p>
    <p>&nbsp;</p>
    <h2>Data Exchange and Inter-Process Communication (IPC)</h2>
    <p>
        Data exchange refers to the process of transferring data between different systems or applications. This can
        involve
        sending data from one system to another, receiving data from an external source, or synchronizing data between
        multiple systems. Data exchange is a fundamental aspect of data integration, as it enables disparate systems to
        share and access information in a seamless and efficient manner.
    </p>
    <p>
        One of the early challenges of data exchange was the lack of standardized formats and protocols for transferring
        data between systems. This led to compatibility issues, data loss, and errors during the data exchange process.
        To address these challenges, various data exchange formats and protocols have been developed to facilitate
        interoperability between systems.
    </p>
    <p>
        Matching these data formats and protocols to the needs of the systems involved in the data exchange process is
        necessary for ensuring smooth and efficient data transfer. <strong>Data transformation</strong> and mapping
        tools can be used to
        convert data from one format to another, enabling systems with different data structures to communicate and
        exchange information effectively. Data transformation involves converting data from one format to another. It is
        not just about changing the format of the data, but also about transforming the data to meet the requirements of
        the target system. This may involve careful cleaning, filtering, aggregating, or enriching the data to ensure
        that it is accurate, complete, and consistentm without changing the meaning or context of the data.
    </p>
    <p>&nbsp;</p>
    <h2>ETL</h2>
    <p>
        ETL stands for Extract, Transform, Load. It is a process used to extract data from one or more sources,
        transform it into a format that is suitable for analysis, and load it into a target system, such as a data
        warehouse or database. ETL is commonly used in data integration and business intelligence to consolidate and
        analyze data from multiple sources.
    </p>
    <p>
        The ETL process typically involves the following steps:
    <ul>
        <li><strong>Extract</strong>: Data is extracted from one or more sources, such as databases, files, or APIs.
        </li>
        <li><strong>Transform</strong>: The extracted data is transformed into a format that is suitable for analysis.
            This may involve cleaning, filtering, aggregating, or enriching the data to ensure its quality and
            consistency.</li>
        <li><strong>Load</strong>: The transformed data is loaded into a target system, such as a data warehouse or
            database, where it can be analyzed and queried.</li>
    </ul>
    </p>
    <p>&nbsp;</p>
    <h2>Self-Describing Data Formats</h2>
    <p>
        In the past, data exchange was often done using proprietary formats that required custom parsers and
        translators to interpret the data. This made data exchange between different systems cumbersome and error-prone.
        Self-describing data file formats were proposed as a solution to this problem. These formats include metadata
        that describe the structure and content of the data, making it easier for systems to interpret and process the
        information.
    </p>
    <h3>XML (extensible markup language)</h3>
    <p>
        XML was one of the first self-describing data formats to gain widespread adoption. XML
        uses tags to define the structure of the data, making it human-readable and machine-parseable.
    </p>
    <h4>XML sample</h4>
    <code>
        &lt;person&gt;
            &lt;name&gt;John Doe&lt;/name&gt;
            &lt;age&gt;30&lt;/age&gt;
            &lt;address&gt;123 Main St.&lt;/address&gt;
        &lt;/person&gt;
    </code>
    <p>
        XML has been widely used for data exchange in various industries, including finance, healthcare, and e-commerce.
        It
        provides a flexible and extensible way to represent structured data, making it suitable for a wide range of
        applications.
    </p>
    <h3>JSON (JavaScript Object Notation)</h3>
    <p>
        XML was followed by JSON, a lightweight data interchange format that is easy for humans to read and write and
        easy
        for machines to parse and generate. JSON is based on a subset of the JavaScript programming language and is
        commonly
        used for web APIs and data exchange between web applications.
    </p>
    <h4>JSON sample</h4>
    <code>
        {
            "person": {
                "name": "John Doe",
                "age": 30,
                "address": "123 Main St."
            }
        }
    </code>
    <p>
        Self-describing data formats like JSON and XML are commonly used for data exchange between different systems.
        These
        formats provide a standardized way to represent and structure data, making it easier for systems to interpret
        and
        process the information. APIs and web services are often used to facilitate data exchange between applications,
        enabling seamless communication and interoperability.
    </p>
    <h2>API (Application Programming Interface)</h2>
    <p>
        An API is a set of rules and protocols that allows one software application to interact with another. APIs
        define
        the methods and data formats that applications can use to communicate with each other. APIs are commonly used to
        enable data exchange between different systems, applications, and services.
    </p>
    <p>
        Much like a web server, an API server listens for requests and responds with data. APIs can be used to retrieve
        data
        from a remote server, send data to a server, or perform specific actions based on the request. APIs are commonly
        used to integrate third-party services, access data from external sources, and enable communication between
        different applications. While a web server will return an HTML page, suitable for a web browser to read, an API
        will
        return data in a format that is more easily consumed by another program.
    </p>
    <p>
        APIs are widely used in web development, mobile app development, and software integration. They provide a
        standardized way for applications to communicate and exchange data, enabling developers to build powerful and
        interconnected systems.
    </p>
    <p>
        Some examples of APIs include:
    <ul>
        <li>https://api.chucknorris.io/jokes/random</li>
        <li>https://dog.ceo/api/breeds/image/random</li>
        <li>https://api.nasa.gov/planetary/apod</li>
        <li>https://api.weather.gov/points/32.8041,-117.1635</li>
        <ul>
            <li>https://api.weather.gov/gridpoints/SGX/57,18/forecast</li>
        </ul>
    </ul>
    </p>
    <h2>Web Services</h2>
    <p style="font-style: italic; text-align: center;">
        What is the difference between an API and a web server?
    </p>
    <p>
        Try this. Open a web browser and type in the URL of a website. Hit enter. What do you see? You see a web page,
        right?
    </p>
    <p>
        Now, open a new tab in your browser and type in the URL of an API. Hit enter. What do you see? You see data,
        right?
    </p>
    <p>
        Open a terminal window and try this:
    </p>
    <pre>
        curl -H "Accept: application/json" https://icanhazdadjoke.com/
    </pre>
    <p>
        You can also try this:
    </p>
    <pre>
        curl -H "Accept: text/html" https://icanhazdadjoke.com/
    </pre>
    <p>
        The first command will return a JSON response, while the second command will return an HTML response. This is
        the difference between an API and a web server. An API returns data in a format that is more easily consumed by
        another program, while a web server returns an HTML page that is suitable for a web browser to read.
    </p>
    <h2>Inter-Process Communication (IPC)</h2>
    <p>
        Inter-Process Communication (IPC) refers to the mechanisms and techniques used by operating systems to allow
        processes to communicate with each other. IPC enables processes to share data, synchronize their actions, and
        coordinate their activities. IPC is essential for enabling communication between different components of a
        system,
        such as applications, services, and system processes.
    </p>
    <p>&nbsp;</p>
    <h2>Healtcare Technologies</h2>
    <p>
        Data integration is particularly crucial in the context of healthcare, where patient information is scattered
        across
        different systems and providers. By integrating data from electronic health records (EHRs), lab systems, imaging
        systems, and other sources, healthcare organizations can create a holistic view of a patient's health history
        and
        treatment journey. This comprehensive view enables healthcare providers to make informed decisions, deliver
        personalized care, and improve patient outcomes.
    </p>
</body>

</html>